# src/exploitation_overlays.py
#
# v5.6 Exploitation Mode Add-ons:
# - Lead-Lag Validator: per-pair lag confidence, drift, false follower tracking
# - Community Risk Manager: correlation community exposure caps + VAR budget
# - PCA Overlay: portfolio factor dominance detection

import numpy as np
import time
import json
from collections import defaultdict

try:
    from sklearn.decomposition import PCA
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    PCA = None

# ---------------------------------------------------------------------
# Lead-Lag Validator
# ---------------------------------------------------------------------
class LeadLagValidator:
    def __init__(self, confidence_floor=0.6, drift_tolerance=1, decay=0.92):
        self.confidence_floor = confidence_floor
        self.drift_tolerance = drift_tolerance
        self.decay = decay
        self.lag_conf = defaultdict(lambda: {"peak_lag": 0, "confidence": 0.0, "false_followers": 0})

    def update(self, leader, follower, lag_signals):
        """
        lag_signals: dict of {lag_step: correlation}
        """
        # find strongest lag
        best_lag, best_corr = None, 0.0
        for lag, corr in lag_signals.items():
            if corr > best_corr:
                best_corr, best_lag = corr, lag

        record = self.lag_conf[(leader, follower)]
        # drift check
        if record["peak_lag"] > 0 and best_lag is not None and abs(best_lag - record["peak_lag"]) > self.drift_tolerance:
            # drift detected, reset confidence
            record["confidence"] *= 0.5
        else:
            record["confidence"] = max(record["confidence"], best_corr)

        if best_lag is not None:
            record["peak_lag"] = best_lag
        # decay confidence each cycle
        record["confidence"] *= self.decay
        return record["confidence"] >= self.confidence_floor

    def mark_false_follower(self, leader, follower):
        self.lag_conf[(leader, follower)]["false_followers"] += 1

    def get_confidence(self, leader, follower):
        return self.lag_conf[(leader, follower)]


# ---------------------------------------------------------------------
# Community Risk Manager
# ---------------------------------------------------------------------
class CommunityRiskManager:
    def __init__(self, corr_threshold=0.7, max_per_community=4, var_budget=0.15):
        self.corr_threshold = corr_threshold
        self.max_per_community = max_per_community
        self.var_budget = var_budget
        self.communities = []

    def detect_communities(self, assets, corr_matrix):
        adjacency = defaultdict(set)
        for (a, b), c in corr_matrix.items():
            if c >= self.corr_threshold:
                adjacency[a].add(b)
                adjacency[b].add(a)

        visited = set()
        communities = []
        for a in assets:
            if a in visited:
                continue
            queue = [a]
            comm = set()
            while queue:
                node = queue.pop()
                if node in visited:
                    continue
                visited.add(node)
                comm.add(node)
                for nbr in adjacency[node]:
                    if nbr not in visited:
                        queue.append(nbr)
            if comm:
                communities.append(comm)
        self.communities = communities
        return communities

    def enforce_caps(self, positions):
        """
        positions: list of dicts {symbol, side, size_usd}
        """
        blocked = []
        for comm in self.communities:
            comm_positions = [p for p in positions if p["symbol"] in comm]
            if len(comm_positions) > self.max_per_community:
                blocked.extend(comm_positions[self.max_per_community:])
            # VAR budget enforcement
            total_var = sum(abs(p["size_usd"]) for p in comm_positions)
            if total_var > self.var_budget * 1e6:  # example budget scaling
                blocked.extend(comm_positions)
        return blocked


# ---------------------------------------------------------------------
# PCA Overlay
# ---------------------------------------------------------------------
class PCAOverlay:
    def __init__(self, dominance_threshold=0.5):
        self.dominance_threshold = dominance_threshold

    def check_dominance(self, returns_matrix):
        """
        returns_matrix: np.array shape (samples, assets)
        """
        if not HAS_SKLEARN or PCA is None:
            print("Warning: sklearn not available, PCA disabled")
            return False, 0.0
        
        pca = PCA()
        pca.fit(returns_matrix)
        explained = pca.explained_variance_ratio_
        dominant = explained[0]
        return dominant >= self.dominance_threshold, dominant

# ---------------------------------------------------------------------
# Example usage
# ---------------------------------------------------------------------
if __name__ == "__main__":
    # Lead-Lag Validator demo
    llv = LeadLagValidator()
    signals = {1: 0.72, 4: 0.65, 12: 0.40}
    print("Lead-Lag valid?", llv.update("BTCUSDT", "ETHUSDT", signals))
    print("Confidence record:", llv.get_confidence("BTCUSDT", "ETHUSDT"))

    # Community Risk Manager demo
    crm = CommunityRiskManager()
    corr_matrix = {("BTCUSDT","ETHUSDT"):0.85, ("BTCUSDT","BNBUSDT"):0.75, ("ETHUSDT","BNBUSDT"):0.80}
    comms = crm.detect_communities(["BTCUSDT","ETHUSDT","BNBUSDT","SOLUSDT"], corr_matrix)
    print("Communities:", comms)
    positions = [{"symbol":"BTCUSDT","side":"long","size_usd":200000},
                 {"symbol":"ETHUSDT","side":"long","size_usd":150000},
                 {"symbol":"BNBUSDT","side":"long","size_usd":120000}]
    print("Blocked positions:", crm.enforce_caps(positions))

    # PCA Overlay demo
    returns = np.random.randn(100,4)  # fake returns
    pca_overlay = PCAOverlay()
    dominant, val = pca_overlay.check_dominance(returns)
    print("Dominant factor?", dominant, "Explained variance:", val)
